{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfca591-dfbf-4430-9b67-1cf88a8cdb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, Model\n",
    "import efficientnet.tfkeras as efn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "size = 100\n",
    "# Load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(\n",
    "    label_mode=\"fine\")\n",
    "\n",
    "\n",
    "\n",
    "x_train = tf.image.resize(x_train, (size, size))\n",
    "x_test = tf.image.resize(x_test, (size, size))\n",
    "\n",
    "#x_train = x_train.astype('float32') / 255.0\n",
    "#x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "\n",
    "# Create data augmentation generator\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15\n",
    ")\n",
    "data_gen.fit(x_train)\n",
    "\n",
    "# Load EfficientNet-B0 without pre-trained weights\n",
    "efficientnet = efn.EfficientNetB3(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
    "\n",
    "# Add a custom classification head\n",
    "x = layers.GlobalAveragePooling2D()(efficientnet.output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = Model(inputs=efficientnet.input, outputs=predictions)\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "combined_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up the callbacks\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"checkpoints/weights.{epoch:02d}.hdf5\", save_freq=20)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, verbose=1, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "csv_logger = CSVLogger(\"plots/training_log.csv\")\n",
    "\n",
    "# Train the model\n",
    "history = combined_model.fit(\n",
    "    data_gen.flow(x_train, y_train, batch_size=64),\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=len(x_train) // 64,\n",
    "    callbacks=[checkpoint, reduce_lr, early_stopping, csv_logger]\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "combined_model.save(\"efficientnetfinetunedB3.h5\")\n",
    "\n",
    "# Plot the learning curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='loss')\n",
    "ax1.plot(history.history['accuracy'], label='accuracy')\n",
    "ax1.set_title('efficientnet Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='train')\n",
    "ax2.plot(history.history['accuracy'], label='validation')\n",
    "ax2.set_title('efficientnet Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.savefig(\"plots/learning_curves.png\")\n",
    "\n",
    "test_loss, test_accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Plot the learning curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='loss')\n",
    "ax1.plot(history.history['accuracy'], label='accuracy')\n",
    "ax1.plot(history.history['lr'], label='learning rate')\n",
    "ax1.set_title('efficientnet')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "plt.savefig(\"plots/learning_curves.png\")\n",
    "\n",
    "test_loss, test_accuracy = combined_model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
